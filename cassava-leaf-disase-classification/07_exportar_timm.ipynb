{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T11:53:02.409978Z",
     "start_time": "2020-12-05T11:53:00.292955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.7.0', '0.3.2')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch \n",
    "from pytorch_lightning.metrics.functional.classification import accuracy\n",
    "from tqdm import tqdm\n",
    "from src import DataModule, TIMM\n",
    "import torchvision\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "import glob\n",
    "import timm\n",
    "\n",
    "torch.__version__, timm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet18-256-pseudo-val_acc=0.85781.ckpt']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = glob.glob('resnet18*-pseudo-*.ckpt')\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T11:53:42.146445Z",
     "start_time": "2020-12-05T11:53:39.799933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"backbone\":        resnet18\n",
       "\"batch_size\":      256\n",
       "\"es_start_from\":   0\n",
       "\"lr\":              0.0003\n",
       "\"max_epochs\":      50\n",
       "\"num_workers\":     20\n",
       "\"optimizer\":       Adam\n",
       "\"patience\":        3\n",
       "\"precision\":       16\n",
       "\"pseudolabelling\": 1\n",
       "\"size\":            256\n",
       "\"subset\":          0.1\n",
       "\"train_trans\":     {'RandomCrop': {'height': 256, 'width': 256}, 'HorizontalFlip': {}, 'VerticalFlip': {}, 'Normalize': {}}\n",
       "\"val_batches\":     5\n",
       "\"val_trans\":       {'CenterCrop': {'height': 256, 'width': 256}, 'Normalize': {}}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TIMM.load_from_checkpoint(checkpoint_path='resnet18-256-pseudo-val_acc=0.85781.ckpt')\n",
    "model.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T11:53:30.817519Z",
     "start_time": "2020-12-05T11:53:30.755521Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  21642\n",
      "Validation samples:  5411\n"
     ]
    }
   ],
   "source": [
    "dm = DataModule(\n",
    "    file = 'data_extra', \n",
    "    batch_size=64,\n",
    "    val_trans={\n",
    "        'CenterCrop': {\n",
    "            'height': model.hparams.size, \n",
    "            'width': model.hparams.size\n",
    "        },\n",
    "        'Normalize': {}\n",
    "    }\n",
    ")\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T17:56:42.435822Z",
     "start_time": "2020-12-02T17:55:58.176523Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    " def evaluate(model, dl):   \n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    acc = []\n",
    "    with torch.no_grad():\n",
    "        t = tqdm(dl)\n",
    "        for x, y in t:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            y_hat = model(x)\n",
    "            acc.append(accuracy(y_hat, y).item())\n",
    "            t.set_description(f\"acc {np.mean(acc):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc 0.79912: 100%|██████████| 85/85 [00:38<00:00,  2.21it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, dm.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate_tta(model, ds, tta = 0, limit = 1):   \n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    acc = []\n",
    "    with torch.no_grad():\n",
    "        t = tqdm(range(len(ds)))\n",
    "        for ix in t:\n",
    "            y = ds[ix][1].unsqueeze(0).cuda()\n",
    "            imgs = torch.stack([ds[ix][0] for i in range(tta+1)]).cuda()\n",
    "            y_hat = model(imgs).mean(axis=0).unsqueeze(0)\n",
    "            acc.append(accuracy(y_hat, y).item())\n",
    "            t.set_description(f\"acc {np.mean(acc):.5f}\")\n",
    "            if ix >= int(limit*len(ds)):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc 0.82288:  10%|▉         | 541/5411 [00:23<03:35, 22.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8228782287822878"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_tta(model, dm.val_ds, limit=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc 1.00000:   0%|          | 1/5411 [00:00<09:41,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  21642\n",
      "Validation samples:  5411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc 0.84686:  10%|▉         | 541/5411 [01:04<09:36,  8.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8468634686346863"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataModule(\n",
    "    file = 'data_extra', \n",
    "    val_trans={\n",
    "        'RandomCrop': {\n",
    "            'height': model.hparams.size, \n",
    "            'width': model.hparams.size\n",
    "        },\n",
    "        'HorizontalFlip': {},\n",
    "        'VerticalFlip': {},\n",
    "        'Normalize': {}\n",
    "    }\n",
    ")\n",
    "dm.setup()\n",
    "\n",
    "evaluate_tta(model, dm.val_ds, tta = 10, limit=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T17:56:42.450820Z",
     "start_time": "2020-12-02T17:56:42.437822Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class FinalModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.trans = torch.nn.Sequential(\n",
    "            torchvision.transforms.CenterCrop(256),\n",
    "            torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        )\n",
    "        self.trans_tta = torch.nn.Sequential(\n",
    "            torchvision.transforms.RandomCrop(256),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.RandomVerticalFlip(),\n",
    "            torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, tta : int = 0):\n",
    "        x = x.float() / 255.\n",
    "        x = x.permute(2, 0, 1)\n",
    "        if tta == 0:\n",
    "            imgs = self.trans(x).unsqueeze(0)\n",
    "            y_hat = self.model(imgs)[0]\n",
    "        else:\n",
    "            imgs = torch.stack([self.trans_tta(x) for i in range(tta)])\n",
    "            y_hat = self.model(imgs).mean(dim=0)\n",
    "        return torch.argmax(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T17:56:42.770930Z",
     "start_time": "2020-12-02T17:56:42.755923Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def evaluate_script(model, ds, tta = 0, limit = 1.):   \n",
    "    model.eval()\n",
    "    #model.cuda()\n",
    "    acc = []\n",
    "    inv_normalize = torchvision.transforms.Normalize(\n",
    "        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
    "        std=[1/0.229, 1/0.224, 1/0.255]\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        t = tqdm(range(len(ds)))\n",
    "        for ix in t:\n",
    "            x, y = ds[ix]\n",
    "            #x, y = x.cuda(), y.cuda()\n",
    "            # simulate test\n",
    "            x = inv_normalize(x)\n",
    "            x *= 255. \n",
    "            x = x.permute(1, 2, 0).long()\n",
    "            #print(x.shape, x.dtype, x.max(), x.min())\n",
    "            y_hat= model(x, tta)\n",
    "            acc.append((y_hat == y).item())\n",
    "            t.set_description(f\"acc {np.mean(acc):.5f}\")\n",
    "            \n",
    "            if ix >= int(limit*len(ds)):\n",
    "                break\n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T17:56:42.754922Z",
     "start_time": "2020-12-02T17:56:42.453823Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc 1.00000:   0%|          | 3/5411 [00:00<03:08, 28.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  21642\n",
      "Validation samples:  5411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc 0.80996:  10%|▉         | 541/5411 [00:16<02:26, 33.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8099630996309963"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = FinalModel(model.m.cpu())\n",
    "\n",
    "dm = DataModule(\n",
    "    file = 'data_extra', \n",
    "    val_trans=None\n",
    ")\n",
    "dm.setup()\n",
    "\n",
    "evaluate_script(final_model, dm.val_ds, limit=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = torch.jit.script(final_model.cpu())\n",
    "torch.jit.save(script, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T17:57:25.971483Z",
     "start_time": "2020-12-02T17:56:42.771930Z"
    }
   },
   "outputs": [],
   "source": [
    "loaded = torch.jit.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc 0.80996:  10%|▉         | 541/5411 [00:15<02:22, 34.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8099630996309963"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_script(loaded, dm.val_ds, limit=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "acc 0.84793:   4%|▍         | 217/5411 [01:00<24:13,  3.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-76a0e7b215d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-8a14fdb488c4>\u001b[0m in \u001b[0;36mevaluate_script\u001b[0;34m(model, ds, tta, limit)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;31m#x, y = x.cuda(), y.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# simulate test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/kaggle/cassava-leaf-disase-classification/src/dm.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, ix)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/albumentations/core/transforms_interface.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                     )\n\u001b[1;32m     88\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_with_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/albumentations/core/transforms_interface.py\u001b[0m in \u001b[0;36mapply_with_params\u001b[0;34m(self, params, force_apply, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mtarget_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_target_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mtarget_dependencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_dependence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtarget_dependencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/albumentations/augmentations/transforms.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, image, **params)\u001b[0m\n\u001b[1;32m   1494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pixel_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_transform_init_args_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/albumentations/augmentations/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(img, mean, std, max_pixel_value)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate_script(loaded, dm.val_ds, tta=10, limit=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T17:57:25.986996Z",
     "start_time": "2020-12-02T17:57:25.973484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('./data/test_images')\n",
    "images = os.listdir(path)\n",
    "images_paths = [str(path/img) for img in images]\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T17:57:26.002995Z",
     "start_time": "2020-12-02T17:57:25.988996Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, imgs, tta=0, bs=32):   \n",
    "    model.eval()\n",
    "    #model.cuda()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for img in imgs:\n",
    "            img = torch.from_numpy(io.imread(img))#.cuda()\n",
    "            y_hat = model(img, tta)#.cpu()\n",
    "            preds.append(y_hat.item())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T17:57:26.252996Z",
     "start_time": "2020-12-02T17:57:26.005998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = torch.jit.load('model.pt')\n",
    "preds = predict(loaded, images_paths)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T17:57:26.268997Z",
     "start_time": "2020-12-02T17:57:26.253996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      2"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'image_id': images, 'label': preds })\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T17:57:26.284996Z",
     "start_time": "2020-12-02T17:57:26.269997Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
